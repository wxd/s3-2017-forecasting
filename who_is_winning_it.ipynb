{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who's winning it? Forecasting sports tournaments\n",
    "\n",
    "*S3, Pozega, Croatia. July 19-27, 2017*\n",
    "\n",
    "The goal of this project is to build a probabilistic forecast of the EURO 2016 football tournament using the historical data about international football matches. The data are used to estimate team strength and to build a goal prediction model. The forecast probabilities are estimated with Monte Carlo simulation.\n",
    "\n",
    "## Building the data-driven components of the system\n",
    "\n",
    "We have got the scores for all international football matches since 1870s. We first use these data to estimate team strength using the Elo ranking method. Then, we use the Elo ratings to build a goal prediction model.\n",
    "\n",
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = pd.read_csv('international+euro16.csv',\n",
    "                     names=['type_long', 'type', 'date', 'team1', 'team2', 'goals1', 'goals2'],\n",
    "                     sep=',', header=None,\n",
    "                     parse_dates=[2], index_col=[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(scores.shape)\n",
    "print(scores.dtypes)\n",
    "scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Elo ranking\n",
    "\n",
    "The Elo rating of a team represents its strength. The probability that Team 1 with rating $R_1$ beats Team 2 with rating $R_2$ at home is calculated as follows: $$P(\\text{Team 1 beats Team 2}) = \\frac{1}{1+{10}^{-(R_1+H-R_2)/400}}$$\n",
    "\n",
    "The rating of a team is updated after each match based on the strength of the opponent, the outcome, and a number of parameters: $$\\Delta R_1=(O_\\text{actual}-O_\\text{expected}) \\times K \\times I \\times N \\times G$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Rinitial=1500\n",
    "\n",
    "def expected_outcome(r, ro):\n",
    "    return  1/(1+10**((ro-r)/400))\n",
    "\n",
    "def probabilities(exp_outcome):\n",
    "    p_draw = exp_outcome * (1 - exp_outcome) * 4/3\n",
    "    p_win = exp_outcome - 0.5 * p_draw\n",
    "    p_loss = 1 - p_draw - p_win\n",
    "    return { 1: p_win, 0.5: p_draw, 0: p_loss }\n",
    "\n",
    "def outcome(g,go):\n",
    "    if g > go:\n",
    "        outcome = 1\n",
    "    elif g < go:\n",
    "        outcome = 0\n",
    "    else:\n",
    "        outcome = 0.5\n",
    "    \n",
    "    return (outcome)\n",
    "\n",
    "def updateElo(r,ro,g,go,game_type,K,I):\n",
    "    actual_outcome = outcome(g,go)\n",
    "    expected_outcome_ = expected_outcome(r,ro)\n",
    "    \n",
    "    if g >= 5:\n",
    "        N = 1\n",
    "    elif g == 4:\n",
    "        N = 0.85\n",
    "    elif g == 3:\n",
    "        N = 0.60\n",
    "    elif g == 2:\n",
    "        N = 0.50\n",
    "    else:\n",
    "        N = 0.40\n",
    "    \n",
    "    goal_difference = abs(g-go)\n",
    "    if goal_difference >= 5:\n",
    "        G=1.5\n",
    "    elif goal_difference == 4:\n",
    "        G=1.35\n",
    "    elif goal_difference == 3:\n",
    "        G=1.20\n",
    "    elif goal_difference == 2:\n",
    "        G=1.05\n",
    "    else:\n",
    "        G=1\n",
    "    \n",
    "    return (actual_outcome - expected_outcome_)*K*I[game_type]*N*G\n",
    "\n",
    "def newElo(r1,r2,g1,g2,game_type,K,I,H):\n",
    "    if game_type == 'Friendly' or 'Qualifier' in game_type:\n",
    "        r1_ = r1 + H\n",
    "    else:\n",
    "        r1_ = r1\n",
    "        \n",
    "    return r1 + updateElo(r1_,r2,g1,g2,game_type,K,I), r2 + updateElo(r2,r1_,g2,g1,game_type,K,I)\n",
    "\n",
    "def eloRatings(scores,K,I,H,return_elo_columns=False):\n",
    "    '''Building Elo ratings using `scores` as the training data and `K` and `H` as parameters'''\n",
    "    elos = {}\n",
    "    elos1 = []\n",
    "    elos2 = []\n",
    "\n",
    "    for index, row in scores.iterrows():\n",
    "        t1 = row['team1']\n",
    "        t2 = row['team2']\n",
    "        r1 = elos.get(t1, Rinitial)\n",
    "        r2 = elos.get(t2, Rinitial)\n",
    "        \n",
    "        if return_elo_columns:\n",
    "            elos1.append(r1)\n",
    "            elos2.append(r2)\n",
    "        \n",
    "        r1_new, r2_new = newElo(r1, r2, row['goals1'], row['goals2'],row['type_long'],K,I,H)\n",
    "        elos[t1] = r1_new\n",
    "        elos[t2] = r2_new\n",
    "\n",
    "    return elos, elos1, elos2\n",
    "\n",
    "def top_elo_teams(ratings,k=10):\n",
    "    '''Return top-`k` teams according to Elo ratings in `ratings`'''\n",
    "    by_rating = sorted(ratings.keys(), key=lambda country: ratings[country], reverse=True)\n",
    "    return [(country, ratings[country]) for country in by_rating[0:k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "equal_game_type_weights = {\n",
    "    'Africa':1 ,\n",
    "    'AfricaQualifier':1 ,\n",
    "    'America':1 ,\n",
    "    'AmericaQualifier':1 ,\n",
    "    'Asia':1 ,\n",
    "    'AsiaQualifier':1 ,\n",
    "    'Confederations':1 ,\n",
    "    'ConfederationsQualifier':1 ,\n",
    "    'Europe':1 ,\n",
    "    'EuropeQualifier':1 ,\n",
    "    'Friendly':1 ,\n",
    "    'Oceania':1 ,\n",
    "    'OceaniaQualifier':1 ,\n",
    "    'SouthAmerica':1 ,\n",
    "    'SouthAmericaQualifier':1 ,\n",
    "    'World':1 , \n",
    "    'WorldQualifier':1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elo1, elo2 = [1767, 1686]\n",
    "print(expected_outcome(elo1, elo2))\n",
    "print(newElo(elo1, elo2, 2, 1, 'Friendly', K=30, I=equal_game_type_weights, H=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning the parameters\n",
    "\n",
    "We split the entire data into training data and validation data. We built the ratings using the training set and pick the parameter values that yield the lowest prediction error on the validation set as measured by *log loss*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_end   = '2013-12-31'\n",
    "\n",
    "validation_start = '2014-01-01'\n",
    "validation_end   = '2016-06-08'\n",
    "validation_set   = scores[validation_start:validation_end]\n",
    "validation_size  = validation_set.shape[0]\n",
    "\n",
    "test_start = '2016-06-10'\n",
    "test_set   = scores[test_start:]\n",
    "test_size  = test_set.shape[0]\n",
    "\n",
    "validation_size, test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log10\n",
    "\n",
    "def logLoss(p, eps=10**(-15)):\n",
    "    p_nonzero = max(min(p, 1-eps), eps)\n",
    "    return log10(p_nonzero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_guess_loss = -logLoss(1/3)\n",
    "random_guess_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def elo_log_loss(ratings_, matches, K, I, H):\n",
    "    num_matches = matches.shape[0]\n",
    "    \n",
    "    ratings=ratings_.copy()\n",
    "    log_loss = 0\n",
    "    for index, row in matches.iterrows():\n",
    "        t1 = row['team1']\n",
    "        t2 = row['team2']\n",
    "        r1 = ratings.get(t1, Rinitial)\n",
    "        r2 = ratings.get(t2, Rinitial)\n",
    "        \n",
    "        g1 = row['goals1']\n",
    "        g2 = row['goals2']\n",
    "        \n",
    "        actual_outcome=outcome(g1,g2)\n",
    "        forecast=probabilities(expected_outcome(r1,r2))[actual_outcome]\n",
    "        log_loss = log_loss + logLoss(forecast)\n",
    "        \n",
    "        r1_new, r2_new = newElo(r1, r2, row['goals1'], row['goals2'], row['type_long'], K=K, I=I, H=H)\n",
    "        ratings[t1] = r1_new\n",
    "        ratings[t2] = r2_new\n",
    "        \n",
    "    return -log_loss / num_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "different_type_weights = [\n",
    "    equal_game_type_weights,\n",
    "    {'Africa': 1.25,\n",
    "     'AfricaQualifier': 1,\n",
    "     'America': 1.25,\n",
    "     'AmericaQualifier': 1,\n",
    "     'Asia': 1.25,\n",
    "     'AsiaQualifier': 1,\n",
    "     'Confederations': 2,\n",
    "     'ConfederationsQualifier': 2,\n",
    "     'Europe': 3,\n",
    "     'EuropeQualifier': 2.5,\n",
    "     'Friendly': 1,\n",
    "     'Oceania': 1.5,\n",
    "     'OceaniaQualifier': 1.25,\n",
    "     'SouthAmerica': 2.75,\n",
    "     'SouthAmericaQualifier': 2.4,\n",
    "     'World': 3.5,\n",
    "     'WorldQualifier': 2.75,\n",
    "     },\n",
    "    {'Africa': 0.6,\n",
    "     'AfricaQualifier': 0.35,\n",
    "     'America': 0.6,\n",
    "     'AmericaQualifier': 0.35,\n",
    "     'Asia': 0.6,\n",
    "     'AsiaQualifier': 0.35,\n",
    "     'Confederations': 1,\n",
    "     'ConfederationsQualifier': 1,\n",
    "     'Europe': 1.25,\n",
    "     'EuropeQualifier': 1,\n",
    "     'Friendly': 0.25,\n",
    "     'Oceania': 0.5,\n",
    "     'OceaniaQualifier': 0.25,\n",
    "     'SouthAmerica': 1.15,\n",
    "     'SouthAmericaQualifier': 0.85,\n",
    "     'World': 1.5,\n",
    "     'WorldQualifier': 1,\n",
    "     },\n",
    "    {'Africa': 3,\n",
    "     'AfricaQualifier': 2,\n",
    "     'America': 2.5,\n",
    "     'AmericaQualifier': 1.75,\n",
    "     'Asia': 2.5,\n",
    "     'AsiaQualifier': 1.75,\n",
    "     'Confederations': 4,\n",
    "     'ConfederationsQualifier': 4,\n",
    "     'Europe': 4.5,\n",
    "     'EuropeQualifier': 3.5,\n",
    "     'Friendly': 1.5,\n",
    "     'Oceania': 2.5,\n",
    "     'OceaniaQualifier': 1.75,\n",
    "     'SouthAmerica': 4.75,\n",
    "     'SouthAmericaQualifier': 3.85,\n",
    "     'World': 5,\n",
    "     'WorldQualifier': 4,\n",
    "     },\n",
    "    {'Africa': 1.25,\n",
    "     'AfricaQualifier': 1,\n",
    "     'America': 1.25,\n",
    "     'AmericaQualifier': 1,\n",
    "     'Asia': 1.25,\n",
    "     'AsiaQualifier': 1,\n",
    "     'Confederations': 2,\n",
    "     'ConfederationsQualifier': 2,\n",
    "     'Europe': 2.5,\n",
    "     'EuropeQualifier': 2,\n",
    "     'Friendly': 1,\n",
    "     'Oceania': 1.5,\n",
    "     'OceaniaQualifier': 1.25,\n",
    "     'SouthAmerica': 2.5,\n",
    "     'SouthAmericaQualifier': 2,\n",
    "     'World': 3,\n",
    "     'WorldQualifier': 2.5,\n",
    "     }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm_notebook as tqdm\n",
    "def tqdm(x, **kwargs): return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameter_tuning = 'Fixed values'\n",
    "# parameter_tuning = 'Full search'\n",
    "parameter_tuning = 'Tune individual parameters'\n",
    "\n",
    "if parameter_tuning == 'Fixed values':\n",
    "    best_parameters = [50, 1973, 100, equal_game_type_weights]\n",
    "    print(best_parameters[:3])\n",
    "    print(best_parameters[3])\n",
    "    \n",
    "    best_K, best_year_start, best_H, best_I = best_parameters\n",
    "    best_train_start = str(best_year_start) + '-1-1'\n",
    "    \n",
    "    best_train_set = scores[best_train_start:train_end]\n",
    "    best_elos      = eloRatings(best_train_set,K=best_K,I=best_I,H=best_H)[0]\n",
    "    best_elo_loss  = elo_log_loss(best_elos,validation_set,K=best_K,I=best_I,H=best_H)\n",
    "    print('\\nLog loss on validation set: ELO={0:.4f} RANDOM={1:.4f}'.format(best_elo_loss, random_guess_loss))\n",
    "elif parameter_tuning == 'Full search':\n",
    "    best_log_loss = 2\n",
    "    best_parameters = []\n",
    "\n",
    "    for K in tqdm([1, 5, 10, 16, 25, 50, 56], desc='K', leave=False):\n",
    "        for year_start in tqdm(range(1973,2007,5), desc='Start year', leave=False):\n",
    "            for H in tqdm([0,50,60,100], desc='H', leave=False):\n",
    "                for I in tqdm(different_type_weights, desc='I', leave=False):\n",
    "                    train_start = str(year_start) + '-1-1'\n",
    "                    train_set   = scores[train_start:train_end]\n",
    "\n",
    "                    elos_initial = eloRatings(train_set,K,I,H)[0]\n",
    "                    elo_loss     = elo_log_loss(elos_initial,validation_set,K,I,H)\n",
    "\n",
    "                    if elo_loss < best_log_loss:\n",
    "                        best_log_loss = elo_loss\n",
    "                        best_parameters = [K, year_start, H, I]\n",
    "\n",
    "    print(best_log_loss, random_guess_loss)\n",
    "    for p in best_parameters:\n",
    "        print(p)\n",
    "\n",
    "    best_K, best_year_start, best_H, best_I = best_parameters\n",
    "    best_train_start = str(best_year_start) + '-1-1'\n",
    "elif parameter_tuning == 'Tune individual parameters':\n",
    "    best_log_loss = 2\n",
    "    best_train_start, best_H, best_I = '1973-1-1', 0, equal_game_type_weights\n",
    "    \n",
    "    for K in tqdm([1, 5, 10, 16, 25, 50, 56], desc='K', leave=False):\n",
    "        train_set   = scores[best_train_start:train_end]\n",
    "\n",
    "        elos_initial = eloRatings(train_set,K,best_I,best_H)[0]\n",
    "        elo_loss     = elo_log_loss(elos_initial,validation_set,K,best_I,best_H)\n",
    "\n",
    "        if elo_loss < best_log_loss:\n",
    "            best_log_loss = elo_loss\n",
    "            best_K = K\n",
    "    print('            ERROR  VALUE')\n",
    "    print('Best K:     {1:.4f} {0:d}'.format(best_K, best_log_loss))\n",
    "    \n",
    "    for year_start in tqdm(range(1974,2007,5), desc='Start year', leave=False):\n",
    "        train_start = str(year_start) + '-1-1'\n",
    "        train_set   = scores[train_start:train_end]\n",
    "\n",
    "        elos_initial = eloRatings(train_set,best_K,best_I,best_H)[0]\n",
    "        elo_loss     = elo_log_loss(elos_initial,validation_set,best_K,best_I,best_H)\n",
    "\n",
    "        if elo_loss < best_log_loss:\n",
    "            best_log_loss = elo_loss\n",
    "            best_train_start = str(year_start) + '-1-1'\n",
    "    print('Best start: {1:.4f} {0:s}'.format(best_train_start, best_log_loss))\n",
    "    \n",
    "    for H in tqdm([0,50,60,100], desc='H', leave=False):\n",
    "        train_set   = scores[best_train_start:train_end]\n",
    "\n",
    "        elos_initial = eloRatings(train_set,best_K,best_I,H)[0]\n",
    "        elo_loss     = elo_log_loss(elos_initial,validation_set,K,best_I,H)\n",
    "\n",
    "        if elo_loss < best_log_loss:\n",
    "            best_log_loss = elo_loss\n",
    "            best_H = H\n",
    "    print('Best H:     {1:.4f} {0:d}'.format(best_H, best_log_loss))\n",
    "        \n",
    "    for I in tqdm(different_type_weights, desc='I', leave=False):\n",
    "        train_set   = scores[best_train_start:train_end]\n",
    "\n",
    "        elos_initial = eloRatings(train_set,best_K,I,best_H)[0]\n",
    "        elo_loss     = elo_log_loss(elos_initial,validation_set,best_K,I,best_H)\n",
    "\n",
    "        if elo_loss < best_log_loss:\n",
    "            best_log_loss = elo_loss\n",
    "            best_I=I\n",
    "    print('Best I:     {1:.4f} {0:d}'.format(different_type_weights.index(best_I), best_log_loss))\n",
    "    # print(best_I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error of the forecasting system based on the estimated rating is `0.40`, lower than the error of random guessing of `0.48`. Note that validation shows that accounting for match importance does **not** improve the performance of the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_train_set = scores[best_train_start:validation_end].copy()\n",
    "elos, elo1, elo2 = eloRatings(full_train_set, K=best_K, H=best_H, I=best_I, return_elo_columns=True)\n",
    "print('Size of the full training set (train+validation): {0:d} matches'.format(full_train_set.shape[0]))\n",
    "print('Size of the test set (EURO 2016): {0:d} matches\\n'.format(test_set.shape[0]))\n",
    "\n",
    "full_train_set['elo1'] = elo1\n",
    "full_train_set['elo2'] = elo2\n",
    "\n",
    "test_loss = elo_log_loss(elos, test_set, K=best_K, H=best_H, I=best_I)\n",
    "print('Log loss on the test set:\\n   ELO={0:.4f}\\nRANDOM={1:.4f}'.format(test_loss, random_guess_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for team, elo in top_elo_teams(elos, k=25):\n",
    "    print('{0:25s} = {1:.1f}'.format(team, elo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the goal prediction model\n",
    "\n",
    "We use the training data and the Elo ratings to build the goal prediction model. Using Poisson regression, we estimate the effect of the strength of a given team and its opponent on the number of goals scored. We simulate goals scored with the predicted number of goals as $\\lambda$, the parameter of the Poisson distribution.\n",
    "\n",
    "Note that each match generates two examples for Poisson regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores_reversed = full_train_set[['elo2','elo1','goals2']]\n",
    "scores_reversed.columns = ['elo1', 'elo2', 'goals1']\n",
    "\n",
    "elo_goals = full_train_set[['elo1','elo2','goals1']].append(scores_reversed)\n",
    "elo_goals.columns = ['elo_team', 'elo_opponent', 'goals_team']\n",
    "\n",
    "elo_goals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.genmod.generalized_estimating_equations import GEE\n",
    "from statsmodels.genmod.cov_struct import Independence\n",
    "from statsmodels.genmod.families import Poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poisson_regression = GEE.from_formula(\"goals_team ~ elo_team + elo_opponent\", data=elo_goals, \n",
    "                                      groups=list(range(0, full_train_set.shape[0])) * 2, # Two examples from a match form \n",
    "                                                                                          # a group in Poisson regression\n",
    "                                                                                          # (not used in this project)\n",
    "                                      cov_struct=Independence(), family=Poisson())\n",
    "goals_predictor = poisson_regression.fit()\n",
    "print(goals_predictor.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simulate_goals(elo_team, elo_opponent):\n",
    "    goals_lambda = goals_predictor.predict(pd.DataFrame([{'elo_team': elo_team, 'elo_opponent': elo_opponent}]))\n",
    "    return np.random.poisson(goals_lambda)\n",
    "\n",
    "def simulate_match(elo1, elo2):\n",
    "    return simulate_goals(elo1, elo2), simulate_goals(elo2, elo1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we do not enforce that win probabilities resulting from Poisson simulations are consistent with the probabilities directly predicted by the Elo ratings, they are remarkably close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elo1, elo2 = elos['Bulgaria'], elos['Greece']\n",
    "elo_prediction = probabilities(expected_outcome(elo1, elo2))\n",
    "\n",
    "def outcome_tuple(pair_of_goals):\n",
    "    return outcome(pair_of_goals[0], pair_of_goals[1])\n",
    "\n",
    "N=1000\n",
    "poisson_outcomes, poisson_counts = np.unique(np.array([outcome_tuple(simulate_match(elo1, elo2)) for i in range(0, N)]), \n",
    "                                             return_counts=True)\n",
    "poisson_frequencies = poisson_counts / N\n",
    "poisson_prediction = {}\n",
    "for o in range(0, np.size(poisson_outcomes)):\n",
    "    poisson_prediction[poisson_outcomes[o]] = poisson_frequencies[o]\n",
    "\n",
    "for o,p in elo_prediction.items():\n",
    "    print('{0:.1f} ELO={1:.2f} POISSON={2:.2f}'.format(o, p, poisson_prediction[o]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the simulator\n",
    "\n",
    "The simulator comprises two major components. The first component simulates the group stage, including the tiebreaking rules. The second component simulates the knockout stage\n",
    "\n",
    "### Simulating the group stage\n",
    "See Wikipedia ([1](https://en.wikipedia.org/wiki/UEFA_Euro_2016#Tiebreakers), \n",
    "[2](https://en.wikipedia.org/wiki/UEFA_Euro_2016#Ranking_of_third-placed_teams),\n",
    "[3](https://en.wikipedia.org/wiki/UEFA_Euro_2016_knockout_phase#Format)) \n",
    "for the tournament scheme and the description of tie-breaking rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group_country = [\n",
    "    ['France','Romania','Albania','Switzerland'],\n",
    "    ['England','Russia','Wales','Slovakia'],\n",
    "    ['Germany','Ukraine','Poland','Northern Ireland'],\n",
    "    ['Spain','Czechia','Turkey','Croatia'],\n",
    "    ['Belgium','Italy','Ireland','Sweden'],\n",
    "    ['Portugal','Iceland','Austria','Hungary']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import cmp_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _simulate_goals(name1,name2):\n",
    "    return simulate_match(elos[name1],elos[name2])\n",
    "    \n",
    "def points(goals_team, goals_opponnent):\n",
    "    if (goals_team > goals_opponnent):\n",
    "        return 3\n",
    "    elif goals_team == goals_opponnent:\n",
    "        return 1\n",
    "    else:\n",
    "        return int(0)\n",
    "\n",
    "def diff(g1,g2):\n",
    "    return g1-g2\n",
    "\n",
    "def simulate_score(i):\n",
    "    _scores = []\n",
    "    for t in range(0, 4):\n",
    "        for opp in range(t + 1, 4):\n",
    "            goals_t, goals_opp = _simulate_goals(group_country[i][t],group_country[i][opp])\n",
    "            _scores.append([t, opp, goals_t, goals_opp])\n",
    "    return _scores\n",
    "\n",
    "\n",
    "def calculate_points(scores, t):\n",
    "    p1=sum([points(scores[2], scores[3]) for scores in scores if scores[0] == t])\n",
    "    p2=sum([points(scores[3], scores[2]) for scores in scores if scores[1] == t])\n",
    "    return p1+p2\n",
    "\n",
    "def group_points(t):\n",
    "    _points = []\n",
    "    for i in range (0,4):\n",
    "        _points.append(calculate_points(t,i))\n",
    "    return _points\n",
    "\n",
    "def com_po(i):\n",
    "    return group_points(simulate_score(i))\n",
    "        \n",
    "def duplicates(_points, item):\n",
    "    return [i for i, x in enumerate(_points) if x == item] \n",
    "\n",
    "def finddpu(_points):\n",
    "    for i in range (0,10):\n",
    "        dup = duplicates(_points,i)\n",
    "        if len(dup) == 3:\n",
    "            return dup\n",
    "\n",
    "def get_goals(score, t):\n",
    "    return sum([diff(score[2],score[3]) for score in score if score[0] == t]) +\\\n",
    "        sum ([diff(score[3],score[2]) for score in score if score[1] == t])\n",
    "    \n",
    "def group_diff(t):\n",
    "    _goal_diff = []\n",
    "    for i in range (0,4):\n",
    "        _goal_diff.append (get_goals(t,i))\n",
    "    return _goal_diff\n",
    "\n",
    "def com_dif (i):\n",
    "    return group_diff(simulate_score(i))\n",
    "\n",
    "def simulate_groups():\n",
    "    global_scores = []\n",
    "    global_diff = []\n",
    "    _3points = []\n",
    "    grouporder = []\n",
    "    for i in range(0,6):\n",
    "        _scores = simulate_score(i)\n",
    "        _points = com_po(i)\n",
    "        _goal_diff = com_dif(i)\n",
    "        global_diff.append (_goal_diff[2])\n",
    "        _3points.append (_points[2])\n",
    "        global_scores.append (_scores)\n",
    "        def simulate_group(points):\n",
    "                def sorting_rules1():\n",
    "                    def compare_teams1(t1,t2):\n",
    "                        if points[t1] != points[t2]: \n",
    "                            return (int(points[t1])-int(points[t2]))\n",
    "                        else:\n",
    "                            return 0\n",
    "                    return  sorted(range(0,4),key=cmp_to_key(compare_teams1), reverse=True)  \n",
    "                def sorting_rules3(order, scores, points):\n",
    "                    def compare_teams3(t1,t2):\n",
    "                        t1goals = 0\n",
    "                        t2goals = 0\n",
    "                        for sc in scores: \n",
    "                            i1 = sc.index(t1) if t1 in sc[0:2] else None\n",
    "                            i2 = sc.index(t2) if t2 in sc[0:2] else None\n",
    "                            if i1 is not None and i2 is not None:\n",
    "                                t1goals = sc[i1+2]\n",
    "                                t2goals = sc[i2+2]\n",
    "                            else:\n",
    "                                pass\n",
    "                        return t1goals-t2goals\n",
    "                    return sorted(range(0,4),key=cmp_to_key(compare_teams3), reverse=True)  \n",
    "                return sorting_rules3(sorting_rules1(),_scores,_points)\n",
    "        grouporder.append (simulate_group(_points))\n",
    "    def find3_team():\n",
    "        teams3 = []\n",
    "        for i in range (0,6):\n",
    "            teams3.append(grouporder[i][2])\n",
    "        return teams3\n",
    "    def find_qual12():     \n",
    "        country_key = []\n",
    "        qual_teams = []\n",
    "        for i in range (0,6):\n",
    "            for n in range(0,2):\n",
    "                qual_teams.append ([group_country[i][grouporder[i][n]],str(i)+str(n)])\n",
    "        return qual_teams\n",
    "    def find_qual32():\n",
    "        _3team = []\n",
    "        for i in range (0,4):\n",
    "            _3team.append ([group_country[i][grouporder[i][2]],str(i)+str(2)])\n",
    "        return _3team\n",
    "    def compare_teams4(t1,t2):\n",
    "        if _3points[t1] != _3points[t2]: \n",
    "            return (int(_3points[t1])-int(_3points[t2]))\n",
    "        else:\n",
    "            return 0\n",
    "    def sorting_rules4():\n",
    "        return sorted(range(0,6),key=cmp_to_key(compare_teams4), reverse=True)\n",
    "    return grouporder,sorted(range(0,6),key=cmp_to_key(compare_teams4), reverse=True),find_qual32(),find_qual12()\n",
    "\n",
    "def simulate_group_stage():\n",
    "    _, _, third_placed, first_second_placed = simulate_groups()\n",
    "    \n",
    "    qualified = {}\n",
    "    for team, position_code in third_placed:\n",
    "        qualified[position_code] = team\n",
    "    for team, position_code in first_second_placed:\n",
    "        qualified[position_code] = team\n",
    "    \n",
    "    return qualified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate the group stage once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group_letters = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "qualified = simulate_group_stage()\n",
    "\n",
    "for code in sorted(qualified.keys()):\n",
    "    group = group_letters[int(code[0])]\n",
    "    rank  = int(code[1]) + 1\n",
    "    \n",
    "    print('{0:1s}{1:1d} {2:s}'.format(group, rank, qualified[code]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary for testing\n",
    "actual_group_results = {\n",
    "    '00': 'France',\n",
    "    '01': 'Switzerland',\n",
    "    '10': 'Wales',\n",
    "    '11': 'England',\n",
    "    '12': 'Slovakia',\n",
    "    '20': 'Germany',\n",
    "    '21': 'Poland',\n",
    "    '22': 'Northern Ireland',\n",
    "    '30': 'Croatia',\n",
    "    '31': 'Spain',\n",
    "    '40': 'Italy',\n",
    "    '41': 'Belgium',\n",
    "    '42': 'Republic of Ireland',\n",
    "    '50': 'Hungary',\n",
    "    '51': 'Iceland',\n",
    "    '52': 'Portugal',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulating the knockout stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A,B,C,D,E,F = 0,1,2,3,4,5\n",
    "\n",
    "def third_placed(group_results):\n",
    "    '''Return the comma-separated indices of the group, from which the 3rd-placed teams did qualify'''\n",
    "    return ','.join(sorted([ k[0] for k, _ in group_results.items() if k[1] == '2' ]))\n",
    "\n",
    "group_combinations = {\n",
    "'0,1,2,3': [C,D,A,B],\n",
    "'0,1,2,4': [C,A,B,E],\n",
    "'0,1,2,5': [C,A,B,F],\n",
    "'0,1,3,4': [D,A,B,E],\n",
    "'0,1,3,5': [D,A,B,F],\n",
    "'0,1,4,5': [E,A,B,F],\n",
    "'0,2,3,4': [C,D,A,E],\n",
    "'0,2,3,5': [C,D,A,F],\n",
    "'0,2,4,5': [C,A,F,E],\n",
    "'0,3,4,5': [D,A,F,E],\n",
    "'1,2,3,4': [C,D,B,E],\n",
    "'1,2,3,5': [C,D,B,F],\n",
    "'1,2,4,5': [E,C,B,F],\n",
    "'1,3,4,5': [E,D,B,F],\n",
    "'2,3,4,5': [C,D,F,E]\n",
    "}\n",
    "\n",
    "def choose_3rd(opponent_group, all_third_placed):\n",
    "    '''See the 3rd link to the Wikipedia above'''\n",
    "    return str(group_combinations[all_third_placed][opponent_group]) + '2'\n",
    "    \n",
    "def create_bracket(group_results):\n",
    "    gr = group_results\n",
    "    tp = third_placed(group_results)\n",
    "    \n",
    "    return [(gr['01'], gr['21']),\n",
    "            (gr['30'], gr[choose_3rd(opponent_group=3, all_third_placed=tp)]),\n",
    "            (gr['10'], gr[choose_3rd(opponent_group=1, all_third_placed=tp)]),\n",
    "            (gr['50'], gr['41']),\n",
    "            (gr['20'], gr[choose_3rd(opponent_group=2, all_third_placed=tp)]),\n",
    "            (gr['40'], gr['31']),\n",
    "            (gr['00'], gr[choose_3rd(opponent_group=0, all_third_placed=tp)]),\n",
    "            (gr['11'], gr['51'])]\n",
    "\n",
    "def elo_probability(elo1, elo2):\n",
    "    return expected_outcome(elo1, elo2)\n",
    "\n",
    "def simulate_winner(teams, elo):\n",
    "    team1 = teams[0]\n",
    "    team2 = teams[1]\n",
    "    elo1 = elo.get(team1,0)\n",
    "    elo2 = elo.get(team2,0)\n",
    "    \n",
    "    probability_1_wins = elo_probability(elo1, elo2)\n",
    "    winner = team1 if random() < probability_1_wins else team2\n",
    "    return winner\n",
    "\n",
    "def simulate_bracket(bracket, elo):\n",
    "    new_bracket = bracket\n",
    "    while True:\n",
    "        winners = [simulate_winner(match, elo) for match in new_bracket]\n",
    "        if len(winners) == 1:\n",
    "            return winners[0]\n",
    "        else:\n",
    "            new_bracket = [(winners[2*i], winners[2*i+1]) for i in range(0, len(winners) // 2)]\n",
    "\n",
    "def simulate_knockout(group_results, elo):\n",
    "    '''Simulates the knockout phase and returns the winner of the tournament'''\n",
    "    bracket = create_bracket(group_results)    \n",
    "    winner = simulate_bracket(bracket, elo)\n",
    "    return winner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simulate_tournament():\n",
    "    knockout_bracket = simulate_group_stage()\n",
    "    winner = simulate_knockout(knockout_bracket, elos)\n",
    "    return winner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the title probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "winners = []\n",
    "max_iterations=1000\n",
    "\n",
    "N = 0\n",
    "while N < max_iterations:\n",
    "    winners.append(simulate_tournament())\n",
    "    N = N+1\n",
    "    \n",
    "    if (N<100 and N%10==0) or (N<1000 and N%100==0) or (N>=1000 and N%1000==0):\n",
    "        teams, counts = np.unique(winners, return_counts=True)\n",
    "        frequencies = counts / N\n",
    "    \n",
    "        team_ranking=sorted(range(0, np.size(teams)),key=lambda t:frequencies[t],reverse=True)\n",
    "        for t in team_ranking:\n",
    "            print('{2:4d};{0:17s};{1:.4f}'.format(teams[t], frequencies[t], N), flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
